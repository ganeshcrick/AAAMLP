{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd080f3d284bb9d561234e2b5710bdd0513fa2392303c74e1383e6eafd126f0306c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Label Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mapping ={\n",
    "    \"Freezing\": 0,\"Warm\": 1,\"Cold\": 2,\"Boiling Hot\": 3,\"Hot\": 4,\"Lava Hot\": 5\n",
    "}\n",
    "\n",
    "data_path =  r'C:\\GN\\Projects\\Datasets\\AAAMLP_datasets/'\n",
    "output_path = r'C:\\GN\\Projects\\Datasets\\AAAMLP_outputs/'\n",
    "\n",
    "df = pd.read_csv(data_path+\"cat_train.csv\")\n",
    "\n",
    "df.loc[:,\"ord_2\"] = df['ord_2'].map(mapping)\n",
    "df['ord_2'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ord_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "## Above can be done using below sklean too\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read the data\n",
    "df = pd.read_csv(data_path+\"cat_train.csv\")\n",
    "\n",
    "# LabelEncoder from scikit-learn does not handle NaN values, and ord_2column has NaN values in it\n",
    "# fill NaN values in ord_2 column\n",
    "df[\"ord_2\"].fillna(\"NONE\",inplace = True)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "lbl_enc =  preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S: do not use this directly. fit first, then transform\n",
    "\n",
    "df['ord_2'] = lbl_enc.fit_transform(df['ord_2'].values)\n",
    "\n",
    "df['ord_2'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ord_2'].value_counts()"
   ]
  },
  {
   "source": [
    "## Sparse representation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# create our example feature matrix\n",
    "example = np.array([[0, 0, 1],[1, 0, 0],[1, 0, 1]])\n",
    "# print size in bytes\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total size of sparse csv matrix\n",
    "print(sparse_example.data.nbytes + sparse_example.indptr.nbytes + sparse_example.indices.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows\n",
    "n_rows = 10000\n",
    "# number of columns\n",
    "n_cols = 100000\n",
    "# create random binary matrix with only 5% values as 1\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (sparse_example.data.nbytes + sparse_example.indptr.nbytes + sparse_example.indices.nbytes)\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "source": [
    "## One Hot Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of dense array: 72\nSize of sparse array: 12\nFull size of sparse array: 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "# create binary matrix\n",
    "example = np.array([[0, 0, 0, 0, 1, 0],[0, 1, 0, 0, 0, 0],[1, 0, 0, 0, 0, 0]])\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (sparse_example.data.nbytes + sparse_example.indptr.nbytes + sparse_example.indices.nbytes)\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of dense array: 8000000000\nSize of sparse array: 8000000\nFull size of sparse array: 16000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# create random 1-d array with 1001 different categories (int)\n",
    "example = np.random.randint(1000, size=1000000)\n",
    "# initialize OneHotEncoder from scikit-learn# keep sparse = False to get dense array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "# fit and transform data with dense one hot encoder\n",
    "ohe_example_1 = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size in bytes for dense array\n",
    "print(f\"Size of dense array: {ohe_example_1.nbytes}\")\n",
    "# initialize OneHotEncoder from scikit-learn\n",
    "# keep sparse = True to get sparse array\n",
    "ohe = preprocessing.OneHotEncoder(sparse=True)\n",
    "# fit and transform data with sparse one-hot encoder\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {ohe_example.data.nbytes}\")\n",
    "full_size = (ohe_example.data.nbytes + ohe_example.indptr.nbytes + ohe_example.indices.nbytes)\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                 Contributor_Hot\n",
       "1                Grandmaster_Warm\n",
       "2                    nan_Freezing\n",
       "3                 Novice_Lava Hot\n",
       "4                Grandmaster_Cold\n",
       "                   ...           \n",
       "599995            Novice_Freezing\n",
       "599996         Novice_Boiling Hot\n",
       "599997       Contributor_Freezing\n",
       "599998                Master_Warm\n",
       "599999    Contributor_Boiling Hot\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "## Create new features from Categorical VAriables\n",
    "\n",
    "df = pd.read_csv(data_path+\"cat_train.csv\")\n",
    "df[\"new_feature\"] = (df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str))\n",
    "df.new_feature"
   ]
  },
  {
   "source": [
    "## Steps in Handling Categorical Variables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever you get categorical variables, follow these simple steps:\n",
    "# •fill the NaN values (this is very important!)\n",
    "# •convert them to integers by applying label encoding using LabelEncoder of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN values with something, you might have to take care of them in this step\n",
    "# •create one-hot encoding. Yes, you can skip binarization!\n",
    "# •go for modelling! I mean the machine learning one.\n"
   ]
  }
 ]
}